{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pandas Data Cleaning\n",
    "\n",
    "Load data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Handling Missing Data\n",
    "#### Review\n",
    "\n",
    "This is what we learned in the basics section, this is just a refresher of how we've handled null values before. Feel free to skip this.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "   - df.dropna(): Drop missing values.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Here we are only drop values if all of their values are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785740 non-null  object        \n",
      " 2   job_location           784696 non-null  object        \n",
      " 3   job_via                785733 non-null  object        \n",
      " 4   job_schedule_type      773074 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785692 non-null  object        \n",
      " 11  salary_rate            33067 non-null   object        \n",
      " 12  salary_year_avg        22003 non-null   float64       \n",
      " 13  salary_hour_avg        10662 non-null   float64       \n",
      " 14  company_name           785723 non-null  object        \n",
      " 15  job_skills             668704 non-null  object        \n",
      " 16  job_type_skills        668704 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df.dropna(how='all')\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Right now all we can do is drop values if they're missing. But that's not useful right now because our DataFrame didn't have any.\n",
    "\n",
    "So, what if we wanted to fill the missing values with something else? This is expecially useful so we don't run into errors when dealing with NaN values.\n",
    "\n",
    "#### Fillna\n",
    "\n",
    "#### Notes\n",
    "\n",
    "   - df.fillna(): Fill missing values\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Let's fill in instances where there's no salary info (aka these columns have NaN values salary_rate, salary_year_avg, salary_hour_avg) with 0.\n",
    "\n",
    "We're going to look at a few rows in these 3 columns right now, so we can compare what we've done before to after.\n",
    "\n",
    "We'll use iloc to look at the first 10 rows :20 and the salary information rows 11:14.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0        None              NaN              NaN\n",
       "1        None              NaN              NaN\n",
       "2        None              NaN              NaN\n",
       "3        None              NaN              NaN\n",
       "4        None              NaN              NaN\n",
       "5        None              NaN              NaN\n",
       "6        None              NaN              NaN\n",
       "7        None              NaN              NaN\n",
       "8        None              NaN              NaN\n",
       "9        None              NaN              NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.iloc[:10,11:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the values for the 3 columns with 0 using fillna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785741 non-null  object        \n",
      " 2   job_location           785741 non-null  object        \n",
      " 3   job_via                785741 non-null  object        \n",
      " 4   job_schedule_type      785741 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785741 non-null  object        \n",
      " 11  salary_rate            785741 non-null  object        \n",
      " 12  salary_year_avg        785741 non-null  float64       \n",
      " 13  salary_hour_avg        785741 non-null  float64       \n",
      " 14  company_name           785741 non-null  object        \n",
      " 15  job_skills             785741 non-null  object        \n",
      " 16  job_type_skills        785741 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "fill_values = ['salary_rate', 'salary_year_avg', 'salary_hour_avg']\n",
    "df_filled = df_cleaned.fillna(0)\n",
    "df_filled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we compare the results using iloc again on our new DataFrame. We see that the previous NaN values in the columns ( salary_rate, salary_year_avg, salary_hour_avg) have been replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  salary_rate  salary_year_avg  salary_hour_avg\n",
       "0           0              0.0              0.0\n",
       "1           0              0.0              0.0\n",
       "2           0              0.0              0.0\n",
       "3           0              0.0              0.0\n",
       "4           0              0.0              0.0\n",
       "5           0              0.0              0.0\n",
       "6           0              0.0              0.0\n",
       "7           0              0.0              0.0\n",
       "8           0              0.0              0.0\n",
       "9           0              0.0              0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.iloc[:10,11:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Drop Duplicates\n",
    "\n",
    "#### Notes\n",
    "\n",
    "   - drop_duplicates(): Remove duplicate rows.\n",
    "   - Analysts will often need to clean up data and one of the most common issues we run into is duplicate values.\n",
    "\n",
    "#### Examples\n",
    "\n",
    "Now that we've dealt with NaN values. Let's continue cleaning the data by removing any duplicate rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 785640 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785640 non-null  object        \n",
      " 1   job_title              785640 non-null  object        \n",
      " 2   job_location           785640 non-null  object        \n",
      " 3   job_via                785640 non-null  object        \n",
      " 4   job_schedule_type      785640 non-null  object        \n",
      " 5   job_work_from_home     785640 non-null  bool          \n",
      " 6   search_location        785640 non-null  object        \n",
      " 7   job_posted_date        785640 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785640 non-null  bool          \n",
      " 9   job_health_insurance   785640 non-null  bool          \n",
      " 10  job_country            785640 non-null  object        \n",
      " 11  salary_rate            785640 non-null  object        \n",
      " 12  salary_year_avg        785640 non-null  float64       \n",
      " 13  salary_hour_avg        785640 non-null  float64       \n",
      " 14  company_name           785640 non-null  object        \n",
      " 15  job_skills             785640 non-null  object        \n",
      " 16  job_type_skills        785640 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 92.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates()\n",
    "df_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you compare that with the original DataFrame which had 785741 entries. This new DataFrame df_unique has 785640 entries. It removed 101 entries.\n",
    "\n",
    "Now let's see what would happen if we tried to remove duplicates from job_title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 234674 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        234674 non-null  object        \n",
      " 1   job_title              234674 non-null  object        \n",
      " 2   job_location           234674 non-null  object        \n",
      " 3   job_via                234674 non-null  object        \n",
      " 4   job_schedule_type      234674 non-null  object        \n",
      " 5   job_work_from_home     234674 non-null  bool          \n",
      " 6   search_location        234674 non-null  object        \n",
      " 7   job_posted_date        234674 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  234674 non-null  bool          \n",
      " 9   job_health_insurance   234674 non-null  bool          \n",
      " 10  job_country            234674 non-null  object        \n",
      " 11  salary_rate            234674 non-null  object        \n",
      " 12  salary_year_avg        234674 non-null  float64       \n",
      " 13  salary_hour_avg        234674 non-null  float64       \n",
      " 14  company_name           234674 non-null  object        \n",
      " 15  job_skills             234674 non-null  object        \n",
      " 16  job_type_skills        234674 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_unique = df_filled.drop_duplicates(subset=['job_title'])\n",
    "df_unique.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at it now. It looks like we removed quite a few rows. Now all of these rows have unique job_titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>GCP Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Contractor and Temp work</td>\n",
       "      <td>True</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023-11-07 14:01:59</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smart folks inc</td>\n",
       "      <td>['python', 'sql', 'gcp']</td>\n",
       "      <td>{'cloud': ['gcp'], 'programming': ['python', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Data Engineer  - GCP Cloud</td>\n",
       "      <td>Dearborn, MI</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Florida, United States</td>\n",
       "      <td>2023-03-27 13:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miracle Software Systems, Inc</td>\n",
       "      <td>['sql', 'python', 'java', 'sql server', 'gcp',...</td>\n",
       "      <td>{'cloud': ['gcp', 'bigquery'], 'databases': ['...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>Romania</td>\n",
       "      <td>2023-12-07 13:40:49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Romania</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zitec</td>\n",
       "      <td>['sql', 'nosql', 'gcp', 'azure', 'aws', 'bigqu...</td>\n",
       "      <td>{'cloud': ['gcp', 'azure', 'aws', 'bigquery', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Technology &amp; Operations Business Analyst</td>\n",
       "      <td>Copenhagen, Denmark</td>\n",
       "      <td>via Trabajo.org</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2023-06-05 13:44:34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hempel</td>\n",
       "      <td>['excel', 'powerpoint', 'power bi']</td>\n",
       "      <td>{'analyst_tools': ['excel', 'powerpoint', 'pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via ZipRecruiter</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>True</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2023-04-23 13:02:57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Radwell International, LLC</td>\n",
       "      <td>['sql', 'python', 'r', 'mongodb', 'mongodb', '...</td>\n",
       "      <td>{'analyst_tools': ['excel'], 'cloud': ['azure'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "2         Data Engineer  Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3         Data Engineer  LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4         Data Engineer                             Data Engineer- Sr Jobs   \n",
       "5         Data Engineer                                  GCP Data Engineer   \n",
       "6  Senior Data Engineer                  Senior Data Engineer  - GCP Cloud   \n",
       "7         Data Engineer                                      Data Engineer   \n",
       "8      Business Analyst           Technology & Operations Business Analyst   \n",
       "9        Data Scientist                                  Data Scientist II   \n",
       "\n",
       "                   job_location             job_via         job_schedule_type  \\\n",
       "0                 Watertown, CT     via Work Nearby                 Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico    via BeBee México                 Full-time   \n",
       "2               Berlin, Germany        via LinkedIn                 Full-time   \n",
       "3               San Antonio, TX   via Diversity.com                 Full-time   \n",
       "4                Washington, DC  via Clearance Jobs                 Full-time   \n",
       "5                      Anywhere    via ZipRecruiter  Contractor and Temp work   \n",
       "6                  Dearborn, MI        via LinkedIn                 Full-time   \n",
       "7                      Anywhere        via LinkedIn                 Full-time   \n",
       "8           Copenhagen, Denmark     via Trabajo.org                 Full-time   \n",
       "9                      Anywhere    via ZipRecruiter                 Full-time   \n",
       "\n",
       "   job_work_from_home          search_location     job_posted_date  \\\n",
       "0               False     Texas, United States 2023-06-16 13:44:15   \n",
       "1               False                   Mexico 2023-01-14 13:18:07   \n",
       "2               False                  Germany 2023-10-10 13:14:55   \n",
       "3               False     Texas, United States 2023-07-04 13:01:41   \n",
       "4               False                    Sudan 2023-08-07 14:29:36   \n",
       "5                True                  Georgia 2023-11-07 14:01:59   \n",
       "6               False   Florida, United States 2023-03-27 13:18:18   \n",
       "7                True                  Romania 2023-12-07 13:40:49   \n",
       "8               False                  Denmark 2023-06-05 13:44:34   \n",
       "9                True  New York, United States 2023-04-23 13:02:57   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States           0   \n",
       "1                  False                 False         Mexico           0   \n",
       "2                  False                 False        Germany           0   \n",
       "3                   True                 False  United States           0   \n",
       "4                  False                 False          Sudan           0   \n",
       "5                  False                 False  United States           0   \n",
       "6                  False                 False  United States           0   \n",
       "7                  False                 False        Romania           0   \n",
       "8                  False                 False        Denmark           0   \n",
       "9                  False                 False  United States           0   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                   company_name  \\\n",
       "0              0.0              0.0           Boehringer Ingelheim   \n",
       "1              0.0              0.0     Hewlett Packard Enterprise   \n",
       "2              0.0              0.0       ALPHA Augmented Services   \n",
       "3              0.0              0.0   Southwest Research Institute   \n",
       "4              0.0              0.0                Kristina Daniel   \n",
       "5              0.0              0.0                smart folks inc   \n",
       "6              0.0              0.0  Miracle Software Systems, Inc   \n",
       "7              0.0              0.0                          Zitec   \n",
       "8              0.0              0.0                         Hempel   \n",
       "9              0.0              0.0     Radwell International, LLC   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                                  0   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2  ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3  ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4  ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "5                           ['python', 'sql', 'gcp']   \n",
       "6  ['sql', 'python', 'java', 'sql server', 'gcp',...   \n",
       "7  ['sql', 'nosql', 'gcp', 'azure', 'aws', 'bigqu...   \n",
       "8                ['excel', 'powerpoint', 'power bi']   \n",
       "9  ['sql', 'python', 'r', 'mongodb', 'mongodb', '...   \n",
       "\n",
       "                                     job_type_skills  \n",
       "0                                                  0  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2  {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3  {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4  {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "5  {'cloud': ['gcp'], 'programming': ['python', '...  \n",
       "6  {'cloud': ['gcp', 'bigquery'], 'databases': ['...  \n",
       "7  {'cloud': ['gcp', 'azure', 'aws', 'bigquery', ...  \n",
       "8  {'analyst_tools': ['excel', 'powerpoint', 'pow...  \n",
       "9  {'analyst_tools': ['excel'], 'cloud': ['azure'...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example we don't really need to remove any duplicates right now, but it's important to understand the concept."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
